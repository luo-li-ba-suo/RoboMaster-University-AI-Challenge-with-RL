wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.12.4
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.6.2
    start_time: 1650896557
    t:
      1:
      - 1
      2:
      - 1
      3:
      - 13
      - 16
      4: 3.6.2
      5: 0.12.4
      8:
      - 5
agent:
  desc: null
  value: <__main__.AgentDiscretePPO object at 0x7f4562b7c128>
batch_size:
  desc: null
  value: 256
break_step:
  desc: null
  value: 20000000
cwd:
  desc: null
  value: 2022-04-25_22-22-36
env:
  desc: null
  value: <PreprocessEnv<RMUA_Multi_agent_Env<Robomaster-v0>>>
env_eval:
  desc: null
  value: null
eval_gap:
  desc: null
  value: 64
eval_times1:
  desc: null
  value: 20
eval_times2:
  desc: null
  value: 30
gamma:
  desc: null
  value: 0.98
gpu_id:
  desc: null
  value: O
if_allow_break:
  desc: null
  value: false
if_per_or_gae:
  desc: null
  value: true
if_remove:
  desc: null
  value: false
if_train:
  desc: null
  value: true
lambda_entropy:
  desc: null
  value: 0.02
lambda_gae_adv:
  desc: null
  value: 0.98
learning_rate:
  desc: null
  value: 0.0001
max_memo:
  desc: null
  value: 4096
net_dim:
  desc: null
  value: 128
num_threads:
  desc: null
  value: 8
random_seed:
  desc: null
  value: 1
ratio_clip:
  desc: null
  value: 0.2
repeat_times:
  desc: null
  value: 16
repeat_times_policy:
  desc: null
  value: 5
reward_scale:
  desc: null
  value: 0.5
rollout_num:
  desc: null
  value: 2
soft_update_tau:
  desc: null
  value: 0.00390625
target_step:
  desc: null
  value: 4096
train_actor_step:
  desc: null
  value: 0
